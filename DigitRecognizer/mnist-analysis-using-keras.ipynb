{"metadata":{"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":29188,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a class=\"anchor\" id=\"0\"></a>\n# Digit Recognizer\n\n## Building neural networks in Keras to recognize digits from the MNIST Dataset","metadata":{"_cell_guid":"816a8f4d-7862-4ced-aa8a-5edc4e53e84a","_uuid":"4e5f1239a9f7ed9a537f4bc65a2888bd25957bda"}},{"cell_type":"code","source":"from IPython.display import Image\nfrom IPython.core.display import HTML \nImage(url= \"https://eu-images.contentstack.com/v3/assets/blt6b0f74e5591baa03/blt790f1b7ac4e04301/6543ff50fcf447040a6b8dc7/News_Image_(47).png\", width=600, height=400)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-04-28T16:56:55.965819Z","iopub.execute_input":"2024-04-28T16:56:55.966121Z","iopub.status.idle":"2024-04-28T16:56:55.975638Z","shell.execute_reply.started":"2024-04-28T16:56:55.966078Z","shell.execute_reply":"2024-04-28T16:56:55.974853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This notebook is created to submit a prediction for the Digit Recognizer competition on Kaggle.\n\nThe objective of this competition is stated below:\n\n*Your goal is to correctly identify digits from a dataset of tens of thousands of handwritten images. We’ve curated a set of tutorial-style kernels which cover everything from regression to neural networks. We encourage you to experiment with different algorithms to learn first-hand what works well and how techniques compare.*\n\nThe dataset for this competition is the classic MNIST dataset, described below:\n\n*MNIST (\"Modified National Institute of Standards and Technology\") is the de facto “hello world” dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.*\n\nIt can be assumed that this is the perfect starting block for exploring Deep Neural Networks with Keras. This dataset can also be used to evaluate new classification models as the field of machine learning continues to grow. \n\nTherefore, in this notebook I will build a train a neural network to accurately recognize digits from handwritten images. I hope that this serves as proof that I have a rudimentary understanding of deep neural networks. \n\n\n**Please consider upvoting if this is helpful to you.**","metadata":{}},{"cell_type":"markdown","source":"This notebook builds on the marvelous kernel created by Aditya Soni: [MNIST with Keras for Beginners](https://www.kaggle.com/code/adityaecdrid/mnist-with-keras-for-beginners-99457)\n\nThankyou for helping me understand image recognition via Deep Neural Networks in Keras.","metadata":{}},{"cell_type":"markdown","source":"## Import Necessary Modules\n","metadata":{"_cell_guid":"3ffb80c5-6778-4130-961b-aa17b57c7741","_uuid":"8353a531a6034b1c21239bcf9657a94a718bcece"}},{"cell_type":"code","source":"# Import useful python libraries\nimport numpy as np # Numerical computing\nimport pandas as pd # Data transforming \nimport matplotlib.pyplot as plt # Plotting\nfrom collections import Counter\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nimport seaborn as sns\nfrom subprocess import check_output\n\n# Print the list of files/directories in the \"../input\" directory\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n%matplotlib inline","metadata":{"_cell_guid":"2d75481f-2b19-d824-6a77-a6f8fa1f63f8","_execution_state":"idle","_uuid":"e8e286a4d699f3294f0ff773baba59f015ae11b9","_active":false,"execution":{"iopub.status.busy":"2024-04-25T21:30:40.693123Z","iopub.execute_input":"2024-04-25T21:30:40.693506Z","iopub.status.idle":"2024-04-25T21:30:42.108096Z","shell.execute_reply.started":"2024-04-25T21:30:40.693438Z","shell.execute_reply":"2024-04-25T21:30:42.107100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load the Dataset from CSV","metadata":{"_cell_guid":"f9f804d7-72e7-415f-88b9-f43ded389d39","_uuid":"4375276c8b31c78a81859766e49db726e73cf4b5"}},{"cell_type":"code","source":"# Load the training dataset from input files\ntrain = pd.read_csv(\"../input/train.csv\")\nprint(train.shape)\ntrain.head() # Show first five rows of dataset","metadata":{"_cell_guid":"d2ecfe40-ec05-6623-6f2d-a296d7eeec9e","_execution_state":"idle","_uuid":"1de17f87d4eb39ebb9772e29bbc70186d09ac927","_active":true,"execution":{"iopub.status.busy":"2024-04-25T21:30:43.766501Z","iopub.execute_input":"2024-04-25T21:30:43.766845Z","iopub.status.idle":"2024-04-25T21:30:48.045764Z","shell.execute_reply.started":"2024-04-25T21:30:43.766795Z","shell.execute_reply":"2024-04-25T21:30:48.045065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use 'counter' to count the occurences of each unique label in the 'label' column of 'train' Dataframe\nz_train = Counter(train['label'])\nz_train","metadata":{"_cell_guid":"74d1193c-49c0-4f83-bb76-9280bf544959","_uuid":"8da998a4c8f1e8ee218a6118217516754fb51868","execution":{"iopub.status.busy":"2024-04-25T21:30:51.000692Z","iopub.execute_input":"2024-04-25T21:30:51.000998Z","iopub.status.idle":"2024-04-25T21:30:51.010550Z","shell.execute_reply.started":"2024-04-25T21:30:51.000954Z","shell.execute_reply":"2024-04-25T21:30:51.009880Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a plot counting the number of unique labels in 'label' column\nsns.set_palette('viridis')\nsns.countplot(train['label'])\n\nlabel_counts = train['label'].value_counts()\n\nplt.show()","metadata":{"_cell_guid":"49685d71-7f60-4df4-936e-1903e0d8bc97","_uuid":"94787bc95e72b77062f3c997bab575584f10f5bf","execution":{"iopub.status.busy":"2024-04-25T21:30:52.864486Z","iopub.execute_input":"2024-04-25T21:30:52.864787Z","iopub.status.idle":"2024-04-25T21:30:53.147301Z","shell.execute_reply.started":"2024-04-25T21:30:52.864741Z","shell.execute_reply":"2024-04-25T21:30:53.145927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the testing dataset from input files\ntest= pd.read_csv(\"../input/test.csv\")\nprint(test.shape)\ntest.head()","metadata":{"_cell_guid":"32eef273-6dd8-7bac-df10-691c90a4112f","_execution_state":"idle","_uuid":"3d5c172812a24ca6a65f6b57258a743d7e9da810","_active":false,"execution":{"iopub.status.busy":"2024-04-25T21:30:54.978683Z","iopub.execute_input":"2024-04-25T21:30:54.978990Z","iopub.status.idle":"2024-04-25T21:30:57.641543Z","shell.execute_reply.started":"2024-04-25T21:30:54.978946Z","shell.execute_reply":"2024-04-25T21:30:57.640687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = (train.iloc[:,1:].values).astype('float32') # all pixel values\ny_train = train.iloc[:,0].values.astype('int32') # only labels i.e targets digits\nx_test = test.values.astype('float32')","metadata":{"_cell_guid":"04b01849-64c8-4701-9d1a-4622f827b1a2","_uuid":"9d47ae3027e049f31a0a3046da9db13c72c82e60","_execution_state":"idle","execution":{"iopub.status.busy":"2024-04-25T21:30:59.477835Z","iopub.execute_input":"2024-04-25T21:30:59.478128Z","iopub.status.idle":"2024-04-25T21:30:59.659412Z","shell.execute_reply.started":"2024-04-25T21:30:59.478090Z","shell.execute_reply":"2024-04-25T21:30:59.658753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Disable the dispaly of matplotlib plots inline\n%matplotlib inline\n\n# Generate a grid of images to preview the first 20 samples\nplt.figure(figsize=(12,10))\nx, y = 10, 4\nfor i in range(20):  \n    plt.subplot(y, x, i+1)\n    plt.imshow(x_train[i].reshape((28,28)),interpolation='nearest')\nplt.show()","metadata":{"_cell_guid":"fe3486b1-1e6b-472a-9512-dc893cbdb166","_uuid":"46f3eed5b689e4d69dd9ebaa67665fbcaeadb4fc","execution":{"iopub.status.busy":"2024-04-25T21:31:01.970364Z","iopub.execute_input":"2024-04-25T21:31:01.970683Z","iopub.status.idle":"2024-04-25T21:31:04.188265Z","shell.execute_reply.started":"2024-04-25T21:31:01.970618Z","shell.execute_reply":"2024-04-25T21:31:04.187101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Normalising The Data ","metadata":{"_cell_guid":"ad1ce800-483d-4d53-8e72-aac58e025625","_uuid":"a57bba5834baddf55952760b01ccb7c492f7c7f7"}},{"cell_type":"markdown","source":"For image data like the MNIST dataset, normalization typically involves scaling the pixel values to a range between 0 and 1. This is because the pixel values in grayscale images typically range from 0 to 255, with 0 representing black and 255 representing white. Scaling to a range between 0 and 1 involves dividing each pixel value by 255.","metadata":{}},{"cell_type":"code","source":"# Divide the training and testing sets by 255 to normalise \nx_train = x_train/255.0\nx_test = x_test/255.0","metadata":{"_cell_guid":"2af344a9-8fbe-4b2f-af5e-a108adf04722","_uuid":"29756ff1b015740f63a1e3b0ee707d4ee3ee0aab","_execution_state":"idle","execution":{"iopub.status.busy":"2024-04-25T21:31:07.172487Z","iopub.execute_input":"2024-04-25T21:31:07.172986Z","iopub.status.idle":"2024-04-25T21:31:07.333425Z","shell.execute_reply.started":"2024-04-25T21:31:07.172902Z","shell.execute_reply":"2024-04-25T21:31:07.331956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"_cell_guid":"632d3bf7-9682-4d6d-b51f-b1503190e2b6","_uuid":"e9e6b0fb776f4400788325fe66ac58f90f56388a","_execution_state":"idle","execution":{"iopub.status.busy":"2024-04-25T21:31:09.377894Z","iopub.execute_input":"2024-04-25T21:31:09.378216Z","iopub.status.idle":"2024-04-25T21:31:09.384892Z","shell.execute_reply.started":"2024-04-25T21:31:09.378158Z","shell.execute_reply":"2024-04-25T21:31:09.384198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Printing the shape of the Datasets","metadata":{"_cell_guid":"df775f7c-a839-4a9b-baee-bef876debd08","_uuid":"98a75d9fb3e0ed369ccd0b4bb3f67805a51c8d95"}},{"cell_type":"code","source":"print('x_train shape is:', x_train.shape)\nprint('x_train # of samples:', x_train.shape[0])\nprint('x_test shape is:', x_test.shape)\nprint('x_test # of samples:', x_test.shape[0])\n\n","metadata":{"_cell_guid":"72e903bd-ad8d-4751-ba2d-0deddadd4ab3","_uuid":"ac95a6317ce1baebb4f17d18388028318f48b509","_execution_state":"idle","execution":{"iopub.status.busy":"2024-04-25T21:31:11.084303Z","iopub.execute_input":"2024-04-25T21:31:11.084606Z","iopub.status.idle":"2024-04-25T21:31:11.090778Z","shell.execute_reply.started":"2024-04-25T21:31:11.084563Z","shell.execute_reply":"2024-04-25T21:31:11.089478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reshape the Datasets To Match Keras' Expectations","metadata":{"_cell_guid":"e4e58453-9f36-4265-bdc7-0a3b5337129c","_uuid":"478435d2e2526e99f684a8c063b05ae08a82e8f0"}},{"cell_type":"code","source":"X_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\nX_test = x_test.reshape(x_test.shape[0], 28, 28, 1)","metadata":{"_cell_guid":"5d6167d5-1e96-40e6-af0c-b960567ef033","_uuid":"5e4de6b35dbd4db773e890c4d16840485a4f74ad","_execution_state":"idle","execution":{"iopub.status.busy":"2024-04-25T21:31:27.819201Z","iopub.execute_input":"2024-04-25T21:31:27.819497Z","iopub.status.idle":"2024-04-25T21:31:27.824419Z","shell.execute_reply.started":"2024-04-25T21:31:27.819454Z","shell.execute_reply":"2024-04-25T21:31:27.823441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import Required Libraries from Keras","metadata":{}},{"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\n\n# Set parameters\nbatch_size = 64\nnum_classes = 10\nepochs = 20\ninput_shape = (28, 28, 1)","metadata":{"_cell_guid":"bb79bc10-9ba2-44fe-a349-570520cd8a80","_uuid":"297c1b8aab418daee490ae79f474ca7814d86378","_execution_state":"idle","execution":{"iopub.status.busy":"2024-04-25T21:31:29.681816Z","iopub.execute_input":"2024-04-25T21:31:29.682132Z","iopub.status.idle":"2024-04-25T21:31:31.337384Z","shell.execute_reply.started":"2024-04-25T21:31:29.682088Z","shell.execute_reply":"2024-04-25T21:31:31.336671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert class vectors to binary using One Hot Encoding\ny_train = keras.utils.to_categorical(y_train, num_classes)\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state=42)","metadata":{"_cell_guid":"8c4ecbcb-268c-48e3-ab93-9015e12d0e79","_uuid":"7a5463286287b10f7bdbbbfae8fabf764f6d5b1d","_execution_state":"idle","execution":{"iopub.status.busy":"2024-04-25T21:32:00.572977Z","iopub.execute_input":"2024-04-25T21:32:00.573258Z","iopub.status.idle":"2024-04-25T21:32:00.964507Z","shell.execute_reply.started":"2024-04-25T21:32:00.573223Z","shell.execute_reply":"2024-04-25T21:32:00.963348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building a Neural Network Model","metadata":{"_cell_guid":"4448455e-bbb5-4276-9d71-142d6b724c87","_uuid":"56980ded182bdfd2eeb5b1fe919fdefe5cd5e309"}},{"cell_type":"markdown","source":"Next I will build a convolutional neural network (CNN) model for image classification.\n\nHere's a breakdown of what each part of the model is doing:\n\n1. Model Architecture:\n    * The Sequential model is initialized, which represents a linear stack of layers.\n    * Convolutional layers (Conv2D) are added to extract features from input images. Each convolutional layer uses rectified linear unit (ReLU) activation and the He normal initializer.\n    * Max pooling layers (MaxPool2D) are added to downsample the feature maps.\n    * Dropout layers (Dropout) are added for regularization to prevent overfitting by randomly setting a fraction of input units to zero during training.\n    * Flatten layer (Flatten) is added to flatten the 2D feature maps into a 1D vector.\n    * Dense layers (Dense) are added for classification, with ReLU activation in the hidden layers and softmax activation in the output layer.\n    * Batch normalization (BatchNormalization) is applied to stabilize and accelerate the learning process.\n2. Model Compilation:\n    * The model is compiled with categorical crossentropy loss, RMSprop optimizer, and accuracy metrics.\n3. Learning Rate Reduction:\n    * A callback ReduceLROnPlateau is defined to reduce the learning rate when a metric has stopped improving.\n4. Data Augmentation:\n    * An ImageDataGenerator is initialized for real-time data augmentation. It applies various transformations such as rotation, zooming, shifting, and flipping to augment the training data and increase the diversity of training samples.","metadata":{}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_normal',input_shape=input_shape))\nmodel.add(Conv2D(32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_normal'))\nmodel.add(MaxPool2D((2, 2)))\nmodel.add(Dropout(0.20))\nmodel.add(Conv2D(64, (3, 3), activation='relu',padding='same',kernel_initializer='he_normal'))\nmodel.add(Conv2D(64, (3, 3), activation='relu',padding='same',kernel_initializer='he_normal'))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(128, (3, 3), activation='relu',padding='same',kernel_initializer='he_normal'))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.RMSprop(),\n              metrics=['accuracy'])\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.0001)\n\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=15, # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images","metadata":{"_cell_guid":"097867df-c77b-4ca8-988a-7baea6f4e387","_uuid":"577c7efb2d90f284383906e712a68df6233fe4e0","_execution_state":"idle","execution":{"iopub.status.busy":"2024-04-25T21:32:14.269213Z","iopub.execute_input":"2024-04-25T21:32:14.269527Z","iopub.status.idle":"2024-04-25T21:32:14.630003Z","shell.execute_reply.started":"2024-04-25T21:32:14.269482Z","shell.execute_reply":"2024-04-25T21:32:14.629253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"_cell_guid":"8dd6be49-de4f-4e76-a6c6-5f2dc9d4f304","_uuid":"9197045f0084aa72f0bd8ece8fb03eca9ab08622","_execution_state":"idle","execution":{"iopub.status.busy":"2024-04-25T21:33:23.274905Z","iopub.execute_input":"2024-04-25T21:33:23.275205Z","iopub.status.idle":"2024-04-25T21:33:23.282168Z","shell.execute_reply.started":"2024-04-25T21:33:23.275162Z","shell.execute_reply":"2024-04-25T21:33:23.280950Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datagen.fit(X_train)\nh = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_val,Y_val),\n                              verbose = 1, steps_per_epoch=X_train.shape[0] // batch_size\n                              , callbacks=[learning_rate_reduction],)","metadata":{"_cell_guid":"33d2485e-df3b-415b-bf2c-3cc1d1afddc1","_uuid":"fc13b3bb1a906117ae78cfd03639e165072f2e45","_execution_state":"idle","execution":{"iopub.status.busy":"2024-04-25T21:33:32.495190Z","iopub.execute_input":"2024-04-25T21:33:32.495482Z","iopub.status.idle":"2024-04-25T21:37:17.763202Z","shell.execute_reply.started":"2024-04-25T21:33:32.495440Z","shell.execute_reply":"2024-04-25T21:37:17.761228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Basic Simple Plot And Evaluation","metadata":{"_cell_guid":"e0f319f7-c701-4ce4-b100-a0db07b9edef","_uuid":"4410fb664affc57163466e4949390b9b97a5d291"}},{"cell_type":"code","source":"final_loss, final_acc = model.evaluate(X_val, Y_val, verbose=0)\nprint(\"Final loss: {0:.6f}, final accuracy: {1:.6f}\".format(final_loss, final_acc))","metadata":{"_cell_guid":"19003034-e42b-4ec4-99d6-abefc7411451","_uuid":"0963a61adf30eba3b8c0d885eee69063e086634d","execution":{"iopub.status.busy":"2024-04-25T21:37:35.624894Z","iopub.execute_input":"2024-04-25T21:37:35.625188Z","iopub.status.idle":"2024-04-25T21:37:35.877191Z","shell.execute_reply.started":"2024-04-25T21:37:35.625145Z","shell.execute_reply":"2024-04-25T21:37:35.876445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see from the above evaluation of the trained model on the validation dataset, the model is very accurate. \n\n**Our model was 99.4% accurate in predicting the correct number when compared to the validation dataset.**","metadata":{}},{"cell_type":"markdown","source":"## Looking at the Loss","metadata":{}},{"cell_type":"markdown","source":"Let's take a closer look at the mistakes our model made. We can use a confusion matrix to quickly identify incorrectly predicted values.","metadata":{}},{"cell_type":"code","source":"# Look at confusion matrix \n#Note, this code is taken straight from the SKLEARN website, an nice way of viewing confusion matrix.\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Predict the values from the validation dataset\nY_pred = model.predict(X_val)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred, axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(Y_val, axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(10))","metadata":{"_cell_guid":"2c64c843-e1d0-449f-b5a5-e51955a30caf","_uuid":"f5355803304624fae4bde1b4829d6329433395d6","execution":{"iopub.status.busy":"2024-04-25T21:40:08.739188Z","iopub.execute_input":"2024-04-25T21:40:08.739496Z","iopub.status.idle":"2024-04-25T21:40:10.101382Z","shell.execute_reply.started":"2024-04-25T21:40:08.739452Z","shell.execute_reply":"2024-04-25T21:40:10.100479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see from the confusion matrix that although our model was very accurate, it did make some errors. These are easily identifed in the chart above by looking at the light blue shaded area.\n\n(i.e. Looking at the top row in one instance when the true label was 0, our model predicted 5. In another instance the true label was 0 and our model predicted 8.)","metadata":{}},{"cell_type":"markdown","source":"## Training and Validation Performance Metrics","metadata":{}},{"cell_type":"markdown","source":"We want to take a closer look into how the model's performance changes over the training epochs. This will help us assess if the model is underfitting or overfitting, and whether adjustments to the model or training process are necessary.\n\nAn explanation of the evaluation code is provided below:\n\n1. Print History Keys:\n    * Print the keys of the history object (h), which contains the training metrics collected during model training. These keys typically include 'acc' (training accuracy), 'val_acc' (validation accuracy), 'loss' (training loss), and 'val_loss' (validation loss).\n2. Extract Metrics:\n    * Extract the training accuracy values from the history object.\n    * Extract the validation accuracy values from the history object.\n    * Extract the training loss values from the history object.\n    * Extract the validation loss values from the history object.\n3. Plot Training and Validation Accuracy:\n    * Plot the training accuracy values against the number of epochs.\n    * Plot the validation accuracy values against the number of epochs.\n4. Plot Training and Validation Loss:\n    * Plot the training and validation loss values against the number of epochs.\n    * Plot the training loss values against the number of epochs.\n    * Plot the validation loss values against the number of epochs.","metadata":{}},{"cell_type":"code","source":"print(h.history.keys())\naccuracy = h.history['acc']\nval_accuracy = h.history['val_acc']\nloss = h.history['loss']\nval_loss = h.history['val_loss']\nepochs = range(len(accuracy))\nplt.plot(epochs, accuracy, 'bo', label='Training accuracy')\nplt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.show()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","metadata":{"_cell_guid":"04c6a010-c928-4acb-bfed-3426a474cf18","_uuid":"cfffb6b672be442d54317e6d92b2c0b180a91934","_execution_state":"idle","execution":{"iopub.status.busy":"2024-04-25T21:45:23.169939Z","iopub.execute_input":"2024-04-25T21:45:23.170275Z","iopub.status.idle":"2024-04-25T21:45:23.766262Z","shell.execute_reply.started":"2024-04-25T21:45:23.170231Z","shell.execute_reply":"2024-04-25T21:45:23.765204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict Values","metadata":{"_cell_guid":"755625bf-de66-45ac-96d2-4204d95e2ced","_uuid":"52100b7260f819aeab482023ebc181990d96fcde"}},{"cell_type":"markdown","source":"At this point we will perform prediction on the validation dataset using a trained neural network model. After executing this code segment, Y_pred_classes will contain the predicted class labels for each sample in the validation dataset, and Y_true_classes will contain the true class labels. These can be used for evaluating the performance of the model on the validation dataset, such as calculating accuracy, precision, recall, and F1-score.","metadata":{}},{"cell_type":"code","source":"# Predict the values from the validation dataset\nY_pred = model.predict(X_val)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred, axis = 1)\nY_true_classes = np.argmax(Y_val, axis = 1)","metadata":{"_cell_guid":"fdf357db-a224-4073-9f74-c3b0e748b858","_uuid":"fade6e45a61151bed5bfebfa77fe6e52e44ee1b7","execution":{"iopub.status.busy":"2024-04-25T22:01:16.881709Z","iopub.execute_input":"2024-04-25T22:01:16.882023Z","iopub.status.idle":"2024-04-25T22:01:17.088546Z","shell.execute_reply.started":"2024-04-25T22:01:16.881979Z","shell.execute_reply":"2024-04-25T22:01:17.087870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_pred_classes[:5], Y_true_classes[:5]","metadata":{"execution":{"iopub.status.busy":"2024-04-25T22:01:19.764372Z","iopub.execute_input":"2024-04-25T22:01:19.764709Z","iopub.status.idle":"2024-04-25T22:01:19.770417Z","shell.execute_reply.started":"2024-04-25T22:01:19.764651Z","shell.execute_reply":"2024-04-25T22:01:19.769659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\ntarget_names = [\"Class {}\".format(i) for i in range(num_classes)]\nprint(classification_report(Y_true_classes, Y_pred_classes, target_names=target_names))","metadata":{"_cell_guid":"f1e6858b-0fbb-476c-8e74-56c57c80057f","_uuid":"49e840a9a0c94b05b6dfbb9bb761fee412ea7624","execution":{"iopub.status.busy":"2024-04-25T22:01:22.043148Z","iopub.execute_input":"2024-04-25T22:01:22.043430Z","iopub.status.idle":"2024-04-25T22:01:22.061919Z","shell.execute_reply.started":"2024-04-25T22:01:22.043389Z","shell.execute_reply":"2024-04-25T22:01:22.061074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see from the above observations, that it is theoretically possible to improve upon this model. However, I am quite content with a 99.5% accuracy and will happily move forward with this model.","metadata":{}},{"cell_type":"markdown","source":"# Final Predictions","metadata":{}},{"cell_type":"markdown","source":"Finally we perform predictions on the test dataset using the trained Neural Network Model and save the predictions to a CSV file. ","metadata":{}},{"cell_type":"code","source":"predicted_classes = model.predict_classes(X_test)\nsubmissions=pd.DataFrame({\"ImageId\": list(range(1,len(predicted_classes)+1)),\n                         \"Label\": predicted_classes})\nsubmissions.to_csv(\"submission.csv\", index=False, header=True)","metadata":{"_cell_guid":"7fe384c1-4777-4c9a-a11e-762c448b5265","_uuid":"4cadfded20b04c8dfd1929699330565d774285b9","_execution_state":"idle","execution":{"iopub.status.busy":"2024-04-25T22:12:32.290816Z","iopub.execute_input":"2024-04-25T22:12:32.291137Z","iopub.status.idle":"2024-04-25T22:12:33.770105Z","shell.execute_reply.started":"2024-04-25T22:12:32.291090Z","shell.execute_reply":"2024-04-25T22:12:33.769129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('my_model_1.h5')\njson_string = model.to_json()","metadata":{"_cell_guid":"ebe5f5cb-1603-401f-a2a5-11cf2d957475","_uuid":"b98487e93dceaf5dbee33150dfc7f2aedaf6f80e","execution":{"iopub.status.busy":"2024-04-25T22:01:32.787555Z","iopub.execute_input":"2024-04-25T22:01:32.787907Z","iopub.status.idle":"2024-04-25T22:01:32.838382Z","shell.execute_reply.started":"2024-04-25T22:01:32.787846Z","shell.execute_reply":"2024-04-25T22:01:32.837755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Thank you!","metadata":{"execution":{"iopub.status.busy":"2024-04-25T22:02:50.282634Z","iopub.execute_input":"2024-04-25T22:02:50.282934Z","iopub.status.idle":"2024-04-25T22:02:50.286385Z","shell.execute_reply.started":"2024-04-25T22:02:50.282891Z","shell.execute_reply":"2024-04-25T22:02:50.285581Z"}}}]}